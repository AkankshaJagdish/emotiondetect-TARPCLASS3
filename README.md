# Emotion Recognition From Human Speech Tone

Summary:
This project focuses on developing an emotion recognition system that can detect and classify human emotions from speech tones. In a world where voice user interfaces and user experience technology are on the rise, emotion recognition holds significant importance. The project utilizes machine learning techniques to analyze acoustic features of speech, with a focus on speech emotion recognition (SER).

Key Highlights:

1. The project employs a custom dataset compiled from TESS, RAVDESS, and EMO-DB datasets, containing 9 distinct emotions: "neutral", "calm", "happy", "sad", "angry", "fear", "disgust", "pleasant surprise", and "boredom".
2. A grid search is performed on various classifiers including "SVC", "AdaBoostClassifier", "RandomForestClassifier", "GradientBoostingClassifier", "DecisionTreeClassifier", "KNeighborsClassifier", "MLPClassifier", and "BaggingClassifier" to identify optimal hyperparameters.
3. The primary focus of the analysis is on the acoustic features of speech, contributing to the success of the emotion recognition model.
4. The achieved average accuracy of approximately 94.5% demonstrates the efficacy of the developed k-nearest neighbours (KNN) model in accurately identifying emotions based on speech characteristics.

This project represents a successful implementation of an emotion recognition system for human speech, contributing to the advancement of speech signal analysis and user interaction technology.

Keywords: Speech Emotion Recognition, Machine Learning, Acoustic Features, Custom Dataset, K-Nearest Neighbours Model
